# [D-CEIVE - Data Commercialization ExtractIng ValuE](https://magnusjmj.github.io/Left4DD/D-CEIVE/)

For this project we decided to focus on cybercapitalism and personalized advertisements, as presented by Renée Ridgway(1). We look at how data has become a currency in our digital culture, how this data is being extracted through hidden processes and used by companies to generate profit.

![LifeEnhancer](https://cdn.rawgit.com/MagnusJMJ/Left4DD/2ebc33f5/Pictures/LifeEnhancer.PNG)

![SignUp](https://cdn.rawgit.com/MagnusJMJ/Left4DD/2ebc33f5/Pictures/V%C3%A6lgNoget.PNG)

![Commercials](https://github.com/MagnusJMJ/Left4DD/blob/master/Pictures/Commercialz.PNG)

## Program Description
Our program mimics a signup-process for a fictitious service that presents itself as a an important part of everyday life. The entirety of the signup-process is relatively normal and predictable, though it possesses a more thorough questionnaire than usual. At the end-page the user is met by a visualization of spamming popup-ads. 

The program is essentially baiting the user to share information, which it then stores and monetizes through advertising. This is done in an attempt to make the user think critically about what data they share online. Through this process we explore how personalization functions as a currency in our contemporary digital age, and attempt to shed light on the fact that there are hidden processes, extracting data from user inputs (and behavior).

Data is the oil of the digital age, and is being logged everywhere there is an opportunity for an input. Whenever a service is free, the consumer becomes what Renée Ridgway refers to as a “prosumer”(2). As a prosumer, the user is consuming, as well as producing data, and thereby contributing to the system of personalization.
In this sense we explore how much information a user is willingly sharing, and how they react when confronted with the fact that this information is blatantly being used for advertising, and the users themselves facilitate this by providing data to the system.

Our program emphasizes the fact that people are becoming increasingly desensitized in regards to the sharing of personal information. There is an increasing trend online to “pay” for “free” services with your data. Users are required to enter information before they can access basic functionalities of a program, or sign an unnecessary long “Terms and Condition”-form. These lockouts have conditioned people to think, that it is without consequence to share their information. They believe the data isn’t being used outside the scope of the application, though their information can be used freely by the company.

### How does it work?
The program functions as a normal, albeit long, signup-process, where the user fills in the (more or less) relevant information in different categories. The signup-process requires the user to share various information about themselves, that is then used to create a personalized user-profile. The user can also choose not to submit certain strings of information, if they are uncomfortable doing so.

At the end the user is presented with what they assume is the end-page. This is disrupted by an animation of popup-ads, that increase exponentially in intensity. The visualization on the end-page is ordered in such a way, that whenever the user gives the system an input, that input is stored, and used to “call” upon the ads at the end screen. Here they are being drawn upon the canvas in random positions, at exponentially increasing intervals.
The less information the user shares throughout the process, the less personalized the advertisements on the end screen will be, as the data targeting the user aren’t necessarily available to personalize the process sufficiently.

![FlowChart](https://cdn.rawgit.com/MagnusJMJ/Left4DD/2ebc33f5/Pictures/flowchart_REALFINAL.png)

## Aesthetics of D-CEIVE
Through our work we illustrate how sharing personal information translates into a resource, as it is monetized through marketing. Hereby we express a concern regarding digital marketing culture and big data.

The end screen of our program adopts a generative aesthetic, as it creates a experience based on the interplay of the user-input that loads the personalized ads. This functionality is in line with Galanter’s definition of generative art as: _“Generative art refers to any art practice in which the artist cedes control to a system with functional autonomy that contributes to or results in a complete work of art…”_ (3)
The program is functionally autonomous as it creates the visual aesthetic independently, after the user input has been registered. Through this generative approach it can be said that the art _“builds possible worlds by creating evolutionary rules that produce events that… on one side are unpredictable and amazing, from the other one they mirror the identity and recognizability of the idea, they are the natural representation of…”_ (4). This quote summarises how we use the generativity of the end-page, to create a sensory experience, that intends to affect the user, and make them think critically of the idea and message we try to convey.

The generativity of our visualization can be seen as chaotic and random, though it does possess some amount of ordering, as explained earlier.
We have established a balance between order and chaos - this projects a sensory experience of chaos, while still allowing the user to process the fact, that there is an ordered connection between the signup-process and the ads. This balance of order and chaos is critical, as without this, the program would not be able to properly convey the message to the user, and they would not make the necessary connection between action and consequence.

Parallels can also be drawn to Geoff Cox, who says that:_“Reality is therefore understood to be assembled through montage (as a parallel to dialectical materialism) to make evident its hidden material structures – which otherwise remain obscured by dominant ideology”_ (5)
We attempt to create a contrast between the user sharing the data and the consequences of this. There is a clear dramaturgical split from the signup-process to the dramatization of the immediate consequences of this otherwise innocent act. By doing so we piece together the fragments of normal web-interactions with inputs and data-logging, to, as Cox nicely put it; _“make evident its hidden material structures - which otherwise remain obscured by dominant ideology”_ .

Ideologically most companies’ primary concern is to generate profit. This is combined with the fact that a lot of companies, depending on the internet and other sorts of digital interfaces to communicate with their users, hide a lot of processes. This is mostly done to make it easier for the user to navigate, as they do not have to worry about stuff they don’t directly need to interact with. These factors combine when the companies have streamlined interfaces, with a lot of invisible functionalities. This has the apparent side effect that some of the processes they obscure, extract data and subliminally manipulate users, without their conscious consent. We mimic this tendency by never referencing the underlying process of extraction during the signup-process.

We chose the colour blue, as a reference to the generic colour-scheme of social media sites. “Coincidentally” this aesthetic is also shared with corporate-culture.

## D-CEIVE as a critical work
The product is an attempt to convey the implications of cybercapitalism. As quoted in the text by Renée Ridgway: _“The predominant economic model behind most internet services is to offer the service for free, attract users, collect information about and monitor these users, and monetize this information”_ (6)

Our program exemplifies that even when doing something as innocent as signing up for a program, from a “trusted source”, your personal data might be stored and used without your conscious approval.

Conveying this problem is important, as these processes are hidden from the user, who might not willingly give up the information if they knew what it was used for. Most users are completely oblivious to the fact that during internet activity, their data is being stored.

Furthermore this problem of hidden algorithms is being amplified by the fact, that personalization is being indirectly legitimized by the public’s apparent approval, through continuous use of these services: _“...these ﬁlters limit what we are exposed to and therefore aﬀect our ability to think and learn. In this way, personalisation[sic] has legitimised an online public sphere that is manipulated by algorithms.”_ (7) This is the role Ridgway refers to, as that of the “prosumer”. They actively contribute to the problem, and therefore inflict this situation upon themselves.

From here we can also draw upon a quote by Dave Winer: _”...It is helpful to, think about Twitter as a rope of information — at the outset you assume you can hold on to the rope...then at some point...your hands begin to burn. You realize you cant hold the rope you need to just let go and observe the rope.”_ (sic)(8)

Here we see how digital media streams, and online culture has such a vast amount of impressions, that it’s impossible to keep track of everything. The users ability to comprehend the underlying structures of their online activities are severely compromised by this informational overload. This phenomenon is amplified by the tendency to hide algorithms etc. This can result in a disconnection with the apparent reality of their actions and the consequences of these, which can lead to an apathetic and desensitized approach to information-sharing etc. This can for example be seen in the way people deal with absurdly long “Terms and Condition”-forms, where most people simply choose to ignore the content and sign them, as that is the only possible way to gain access to the services locked away behind them.

This is a problematic position, as most users aren’t aware of their indirect approval and condoning of these algorithms and processes. This lack of awareness of the user’s position as prosumer, as both the fly and the web, is exactly what we try to convey through our program.

At the end screen we try to emphasize the severity of the problem at hand, by establishing a stark contrast through the antagonism of the mundane process of the initial sign-up, and the sensory experience of the noisy visualization.

We used the example of ads in our program, as this is the most common use of data extraction - ads and monetization. Though there are a lot of other possible uses, this better encapsulates our point - that personalisation functions as currency, as shown by Renée Ridgway.

## Notes 
 
1. Ridgway, Renée (2015). In A Peer Reviewed Journal About: Personalisation as Currency. http://www.aprja.net/personalisation-as-currency/ 
2. Ibid p. 8.
3. Galanter, Philip (2016). Generative Art Theory. In: A Companion to Digital Art, First Edition. John Wiley & Sons. p. 154.
4. Ibid, p. 155.
5. Cox, Geoff. (2015) Real-Time for Pirate Cinema. p.8. http://aksioma.org/Geoff-Cox-Real-time-for-Pirate?lang=en 
6. Mikians et al (2012), quoted in Personalisation as Currency. p. 1.
7. Ibid, p. 4.
8. Winer, Dave (2009), quoted in Borthwick: Distribution Now: http://www.borthwick.com/weblog/2009/05/13/699/ 

## Literature
Ridgway, Renée (2015). In A Peer Reviewed Journal About: Personalisation as Currency. http://www.aprja.net/personalisation-as-currency/ 

Galanter, Philip (2016). Generative Art Theory. In: A Companion to Digital Art, First Edition. John Wiley & Sons. 

Cox, Geoff. (2015) Real-Time for Pirate Cinema. http://aksioma.org/Geoff-Cox-Real-time-for-Pirate?lang=en 

Berry, David M. (2015). The philosophy of software: code and mediation in the digital age. Basingstoke: Palgrave Macmillan.

Golbeck, Jennifer (2013), On Secound Thought.: http://www.slate.com/articles/technology/future_tense/2013/12/facebook_self_censorship_what_happens_to_the_posts_you_don_t_publish.html 
